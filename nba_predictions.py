# -*- coding: utf-8 -*-
"""NBA Predictions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZWBmaXz1LfNQTxjZW71oycZdRP6ROf4Z
"""

# %% [1] Imports and Global Settings
import pandas as pd
import numpy as np
import glob
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report

RANDOM_STATE = 42

# %% [2] Load Allowed Features Metadata
metadata_file = "Matchup-metadata.xlsx"  # Update if needed
metadata = pd.read_excel(metadata_file)

# Clean up column headers (strip whitespace)
metadata.columns = metadata.columns.str.strip()
flag_column = 'Can be used in the model'  # The column that flags allowed features
print("Metadata columns:", metadata.columns.tolist())
print(f"Unique values in '{flag_column}':", metadata[flag_column].unique())

# Filter allowed features: those marked with an 'x' (case-insensitive)
allowed_features = metadata.loc[
    metadata[flag_column].astype(str).str.strip().str.lower() == 'x',
    'Feature'
].tolist()
print("Allowed features (from metadata):", allowed_features)

# %% [3] Load and Combine Training Data
# Update this list to include all CSV files from 2007 to 2015 if available
csv_files = [

    "matchups-2007.csv",
    "matchups-2008.csv",
    "matchups-2009.csv"
]
train_list = []
for file in csv_files:
    try:
        df_temp = pd.read_csv(file)
        print(f"Loaded {file} with shape {df_temp.shape}")
        train_list.append(df_temp)
    except Exception as e:
        print(f"Error loading {file}: {e}")

train_df = pd.concat(train_list, ignore_index=True)
print("Combined training data shape:", train_df.shape)

# %% [4] Determine the Target Column (Fifth Player)
# We'll check a few possible column names in your data
home_lineup_full = ['home_0', 'home_1', 'home_2', 'home_3', 'home_4']
target_candidates = ['home_4', 'Fifth_Player', 'Home_Player5']

found_target = None
for tc in target_candidates:
    if tc in train_df.columns:
        found_target = tc
        break

if found_target:
    ml_approach = True
    target_column = found_target
    print("Using ML approach with target column:", target_column)
else:
    ml_approach = False
    print("No recognized fifth-player column found. (Model approach is disabled.)")

# %% [5] Prepare Training Data (if target was found)
if ml_approach:
    # 1) From the allowed features, keep only those that exist in train_df
    #    Also exclude the target column from the feature set (we'll store it separately).
    input_features = [
        feat for feat in allowed_features
        if feat in train_df.columns and feat != target_column
    ]

    # Ensure the first four home lineup columns are present (if they are in train_df)
    # This can help the model know who the first four players are:
    for col in ['home_0', 'home_1', 'home_2', 'home_3']:
        if col in train_df.columns and col not in input_features:
            input_features.append(col)

    print("Input features used for modeling:", input_features)

    # 2) Split into X (features) and y (target)
    X_train_full = train_df[input_features].copy()
    y_train_full = train_df[target_column].copy()

    # 3) Basic cleaning: fill missing values
    #    For object columns, fill with 'Unknown'; for numeric, fill with median
    for col in X_train_full.columns:
        if X_train_full[col].dtype == 'object':
            X_train_full[col] = X_train_full[col].fillna('Unknown')
        else:
            X_train_full[col] = X_train_full[col].fillna(X_train_full[col].median())

    # 4) Label-encode categorical columns
    encoders = {}
    for col in X_train_full.select_dtypes(include=['object']).columns:
        le = LabelEncoder()
        X_train_full[col] = le.fit_transform(X_train_full[col].astype(str))
        encoders[col] = le

    # 5) Label-encode the target (player names)
    target_le = LabelEncoder()
    y_train_full = y_train_full.fillna('Unknown')  # just in case
    y_train_full = target_le.fit_transform(y_train_full)

    print("Training data preprocessing complete.")
    print("Shape of X_train_full:", X_train_full.shape)

# %% [6] Train/Validation Split and Model Training
if ml_approach:
    X_train, X_val, y_train, y_val = train_test_split(
        X_train_full, y_train_full, test_size=0.2, random_state=RANDOM_STATE
    )
    print("Training split shape:", X_train.shape, "Validation split shape:", X_val.shape)

    model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)
    model.fit(X_train, y_train)
    print("RandomForest model training complete.")

    # Evaluate on validation set
    val_preds = model.predict(X_val)
    val_acc = accuracy_score(y_val, val_preds)
    print(f"Validation Accuracy: {val_acc*100:.2f}%")

    # (Optional) Show classification report on validation
    print("Classification Report (Validation):")
    print(classification_report(y_val, val_preds))

# %% [7] Load and Preprocess Test Data
test_df = pd.read_csv("NBA_test.csv")
test_labels_df = pd.read_csv("NBA_test_labels.csv")
print("Test data shape:", test_df.shape)
print("Test labels shape:", test_labels_df.shape)

if ml_approach:
    X_test = test_df.copy()

    # The model is supposed to predict the missing 5th home player, so if "home_4" is present, we drop it
    if "home_4" in X_test.columns:
        X_test.drop(columns=["home_4"], inplace=True)

    # Add any missing columns that are in input_features but not in X_test
    for col in input_features:
        if col not in X_test.columns:
            X_test[col] = np.nan

    # Reorder columns to match training feature order
    X_test = X_test[input_features].copy()

    # Fill missing values (same approach as training)
    for col in X_test.columns:
        if X_test[col].dtype == 'object':
            X_test[col] = X_test[col].fillna('Unknown')
        else:
            X_test[col] = X_test[col].fillna(X_test[col].median())

    # Encode with the same label encoders used in training
    for col in X_test.select_dtypes(include=['object']).columns:
        if col in encoders:
            le = encoders[col]
            # Map unseen categories to -1
            def map_func(x):
                return le.transform([x])[0] if x in le.classes_ else -1
            X_test[col] = X_test[col].apply(map_func)
        else:
            # If somehow there's a categorical column we didn't encode, map all to -1
            X_test[col] = -1

    print("Test data preprocessing complete. Shape of X_test:", X_test.shape)

# %% [8] Predict the Missing Fifth Player
if ml_approach:
    y_pred = model.predict(X_test)
    y_pred_names = target_le.inverse_transform(y_pred)

    # If the test data has columns like Game_ID and Home_Team, let's use them in the final output
    output_cols = {}
    if 'Game_ID' in test_df.columns:
        output_cols['Game_ID'] = test_df['Game_ID']
    if 'Home_Team' in test_df.columns:
        output_cols['Home_Team'] = test_df['Home_Team']

    # Add the predicted fifth player
    output_cols['Fifth_Player'] = y_pred_names
    final_predictions = pd.DataFrame(output_cols)

    # Save to CSV
    final_predictions.to_csv("NBA_predictions.csv", index=False)
    print("Predictions saved to 'NBA_predictions.csv'. Preview:")
    print(final_predictions.head())
else:
    print("No ML approach; skipping predictions.")

# %% [9] Evaluate Against Removed Labels (Ground Truth)
if ml_approach:
    # We'll assume the test_labels_df has the same row order as test_df,
    # and the ground truth column might be "Fifth_Player" or "home_4".
    if "Fifth_Player" in test_labels_df.columns:
        gt_col = "Fifth_Player"
    elif "home_4" in test_labels_df.columns:
        gt_col = "home_4"
    elif "removed_value" in test_labels_df.columns:
        gt_col = "removed_value"  # <-- new condition
    else:
        gt_col = None

    if gt_col is not None:
        ground_truth = test_labels_df[gt_col].fillna('Unknown').astype(str)
        predictions = pd.Series(y_pred_names, dtype=str)
        correct = (predictions == ground_truth).sum()
        total = len(ground_truth)
        final_accuracy = correct / total
        print(f"Test Accuracy (matching removed player): {final_accuracy*100:.2f}%")

        print("Classification Report (Test):")
        # We need to encode ground_truth and predictions to pass into classification_report
        def safe_transform(x):
            return target_le.transform([x])[0] if x in target_le.classes_ else -1
        y_test_true_encoded = ground_truth.apply(safe_transform)
        y_test_pred_encoded = predictions.apply(safe_transform)
        print(classification_report(y_test_true_encoded, y_test_pred_encoded))
    else:
        print("No recognized column for ground truth in test_labels_df.")

# %% [10] Report Matches per Year in Test Data
if "season" in test_df.columns:
    matches_per_year = test_df.groupby("season").size()
    print("\nNumber of test matches (cases) per year:")
    print(matches_per_year)

    avg_matches = matches_per_year.mean()
    print(f"Average number of test matches per year: {avg_matches:.2f}")
else:
    print("No 'season' column found in test_df; cannot report matches per year.")

# %% [11] (Optional) Feature Importances
if ml_approach:
    importances = model.feature_importances_
    feat_imp_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': importances})
    feat_imp_df.sort_values(by='Importance', ascending=False, inplace=True)
    print("\nTop 10 Feature Importances:")
    print(feat_imp_df.head(10))
else:
    print("No ML model was trained; skipping feature importance analysis.")

print("\n--- Execution complete. ---")

# %% [summary] Summarize Important Results

print("\n--- Summary of Key Results ---")

# 1) Training data shape
if 'train_df' in globals():
    print(f"1) Combined Training Data Shape: {train_df.shape}")

# 2) Validation accuracy
if 'val_acc' in globals():
    print(f"2) Validation Accuracy (on validation split): {val_acc*100:.2f}%")

# 3) Test accuracy
if 'final_accuracy' in globals():
    print(f"3) Test Accuracy (matching removed player): {final_accuracy*100:.2f}%")

# 4) Test matches per year
if 'matches_per_year' in globals():
    print("\n4) Number of test matches (cases) per year:")
    print(matches_per_year)
    if 'avg_matches' in globals():
        print(f"Average number of test matches per year: {avg_matches:.2f}")

# 5) Top 10 feature importances
if 'feat_imp_df' in globals():
    print("\n5) Top 10 Feature Importances:")
    print(feat_imp_df.head(10))

print("\n--- End of Summary ---")

